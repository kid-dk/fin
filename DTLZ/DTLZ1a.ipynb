{"cells":[{"cell_type":"code","source":["from google.colab import drive\n","import os, torch, gc\n","import pandas as pd\n","import numpy as np # Import numpy\n","\n","drive.mount('/gdrive')\n","\n","# Define the path to your \"flick\" folder\n","folder_path = '/gdrive/MyDrive/code' # Replace 'MyDrive' with your actual Drive folder name if different\n","\n","# Create the folder if it doesn't exist\n","if not os.path.exists(folder_path):\n","    os.makedirs(folder_path)\n","\n","# Change the current working directory to the \"flick\" folder\n","os.chdir(folder_path)\n","\n","print(f\"Current working directory changed to: {os.getcwd()}\")"],"metadata":{"id":"N3dXjUebLEBV","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1747908122662,"user_tz":-330,"elapsed":1708,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}},"outputId":"9cdab2a2-5a55-4ac5-d3f5-2716a407d90a"},"execution_count":36,"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n","Current working directory changed to: /gdrive/MyDrive/code\n"]}]},{"cell_type":"code","source":["os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n","torch.set_default_dtype(torch.float32)"],"metadata":{"id":"XHcz5o_7NI_x","executionInfo":{"status":"ok","timestamp":1747908122662,"user_tz":-330,"elapsed":5,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"execution_count":37,"outputs":[]},{"cell_type":"code","execution_count":38,"metadata":{"id":"lSxpp8YmBdho","executionInfo":{"status":"ok","timestamp":1747908125678,"user_tz":-330,"elapsed":3019,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"7abd1bf4-8407-4808-aa23-8bb6474018f1"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: botorch in /usr/local/lib/python3.11/dist-packages (0.14.0)\n","Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (4.13.2)\n","Requirement already satisfied: pyre_extensions in /usr/local/lib/python3.11/dist-packages (from botorch) (0.0.32)\n","Requirement already satisfied: gpytorch==1.14 in /usr/local/lib/python3.11/dist-packages (from botorch) (1.14)\n","Requirement already satisfied: linear_operator==0.6 in /usr/local/lib/python3.11/dist-packages (from botorch) (0.6)\n","Requirement already satisfied: torch>=2.0.1 in /usr/local/lib/python3.11/dist-packages (from botorch) (2.6.0+cu124)\n","Requirement already satisfied: pyro-ppl>=1.8.4 in /usr/local/lib/python3.11/dist-packages (from botorch) (1.9.1)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.11/dist-packages (from botorch) (1.15.3)\n","Requirement already satisfied: multipledispatch in /usr/local/lib/python3.11/dist-packages (from botorch) (1.0.0)\n","Requirement already satisfied: threadpoolctl in /usr/local/lib/python3.11/dist-packages (from botorch) (3.6.0)\n","Requirement already satisfied: jaxtyping in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (0.3.2)\n","Requirement already satisfied: mpmath<=1.3,>=0.19 in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.3.0)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (from gpytorch==1.14->botorch) (1.6.1)\n","Requirement already satisfied: numpy>=1.7 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (2.0.2)\n","Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (3.4.0)\n","Requirement already satisfied: pyro-api>=0.1.1 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (0.1.2)\n","Requirement already satisfied: tqdm>=4.36 in /usr/local/lib/python3.11/dist-packages (from pyro-ppl>=1.8.4->botorch) (4.67.1)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.18.0)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.1.6)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2025.3.2)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.3.1.170)\n","Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (0.6.2)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (12.4.127)\n","Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (3.2.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.1->botorch) (1.13.1)\n","Requirement already satisfied: typing-inspect in /usr/local/lib/python3.11/dist-packages (from pyre_extensions->botorch) (0.9.0)\n","Requirement already satisfied: wadler-lindig>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from jaxtyping->gpytorch==1.14->botorch) (0.1.6)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.1->botorch) (3.0.2)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn->gpytorch==1.14->botorch) (1.5.0)\n","Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from typing-inspect->pyre_extensions->botorch) (1.1.0)\n"]}],"source":["# Install dependencies if we are running in colab\n","import sys\n","if 'google.colab' in sys.modules:\n","    %pip install botorch"]},{"cell_type":"markdown","metadata":{"originalKey":"61330204-a407-449f-af77-fcd868546651","showInput":false,"id":"JiijYn5qBdhm"},"source":["## Noisy, Parallel, Multi-Objective BO in BoTorch with qEHVI, qNEHVI, and qNParEGO\n","\n","In this tutorial, we illustrate how to implement a simple multi-objective (MO) Bayesian Optimization (BO) closed loop in BoTorch.\n","\n","We use the parallel ParEGO ($q$ParEGO), parallel Expected Hypervolume Improvement ($q$EHVI), and parallel Noisy Expected Hypervolume Improvement ($q$NEHVI) acquisition functions to optimize a synthetic ZDT2 problem test function with additive Gaussian observation noise over a 30-parameter search space [0,1]^30. See `botorch/test_functions/multi_objective.py` for details on ZDT2.\n","\n","Since botorch assumes a maximization of all objectives, we seek to find the Pareto frontier, the set of optimal trade-offs where improving one metric means deteriorating another.\n","\n","**For batch optimization (or in noisy settings), we strongly recommend using $q$NEHVI rather than $q$EHVI because it is far more efficient than $q$EHVI and mathematically equivalent in the noiseless setting.**"]},{"cell_type":"markdown","metadata":{"originalKey":"f01416cb-e83e-4263-b599-b2a3221d144d","showInput":false,"id":"8_WZ6HzLBdho"},"source":["### Set dtype and device\n","Note: $q$EHVI and $q$NEHVI aggressively exploit parallel hardware and are both much faster when run on a GPU. See [1, 2] for details."]},{"cell_type":"code","execution_count":39,"metadata":{"customOutput":null,"executionStartTime":1668649461840,"executionStopTime":1668649461848,"jupyter":{"outputs_hidden":false},"originalKey":"41c30177-379b-4e63-9996-41bc17d70769","requestMsgId":"7e4820a5-df3b-45a6-9826-42541ee0f4f4","id":"iNZ_9z01Bdhp","executionInfo":{"status":"ok","timestamp":1747908125684,"user_tz":-330,"elapsed":5,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["import os\n","import torch\n","torch.manual_seed(80)\n","\n","\n","tkwargs = {\n","    \"dtype\": torch.double,\n","    \"device\": torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n","}\n","SMOKE_TEST = os.environ.get(\"SMOKE_TEST\")"]},{"cell_type":"markdown","metadata":{"originalKey":"8d895a93-397c-4d2c-b6f5-96f589312538","showInput":false,"id":"B1v64d4oBdhq"},"source":["### Problem setup\n"]},{"cell_type":"code","execution_count":40,"metadata":{"id":"VxqCnTGMBdhq","executionInfo":{"status":"ok","timestamp":1747908125689,"user_tz":-330,"elapsed":3,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["# from botorch.test_functions.multi_objective import DTLZ1\n","# problem = DTLZ1(dim=6, num_objectives=3, negate=True).to(**tkwargs)"]},{"cell_type":"code","source":["import math\n","import torch\n","from torch import Tensor\n","from typing import Optional\n","from scipy.special import gamma\n","from botorch.test_functions.multi_objective import DTLZ\n","from botorch.utils.sampling import sample_simplex, sample_hypersphere\n","\n","class DTLZ1a(DTLZ):\n","    r\"\"\"DTLZ1a: Modified DTLZ1 with 3 objectives and 6 variables.\"\"\"\n","    _ref_val = 400.0\n","\n","    def __init__(self, noise_std: Optional[float] = None, negate: bool = False) -> None:\n","        super().__init__(dim=6, num_objectives=3, noise_std=noise_std, negate=negate)\n","\n","    def _evaluate_true(self, X: Tensor) -> Tensor:\n","        X_m = X[..., -self.k :]\n","        X_m_minus_half = X_m - 0.5\n","        # Modified cosine frequency: use 10*pi instead of 20*pi\n","        sum_term = (X_m_minus_half.pow(2) - torch.cos(10 * math.pi * X_m_minus_half)).sum(dim=-1)\n","        g_X = 100 * (self.k + sum_term)\n","        g_X_term = 0.5 * (1 + g_X)\n","        fs = []\n","        for i in range(self.num_objectives):\n","            idx = self.num_objectives - 1 - i\n","            f_i = g_X_term * X[..., :idx].prod(dim=-1)\n","            if i > 0:\n","                f_i = f_i * (1 - X[..., idx])\n","            fs.append(f_i)\n","        return torch.stack(fs, dim=-1)\n","\n","    def gen_pareto_front(self, n: int) -> Tensor:\n","        f_X = 0.5 * sample_simplex(\n","            n=n,\n","            d=self.num_objectives,\n","            qmc=True,\n","            dtype=self.ref_point.dtype,\n","            device=self.ref_point.device,\n","        )\n","        if self.negate:\n","            f_X *= -1\n","        return f_X\n","\n","    @property\n","    def _max_hv(self) -> float:\n","        return self._ref_val ** self.num_objectives - 1.0 / (2 ** self.num_objectives)\n","\n","\n","problem = DTLZ1a(negate=True).to(**tkwargs)"],"metadata":{"id":"6JGD2OZnBgNx","executionInfo":{"status":"ok","timestamp":1747908125700,"user_tz":-330,"elapsed":9,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"execution_count":41,"outputs":[]},{"cell_type":"code","execution_count":42,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"-WaIKxgPBdhq","executionInfo":{"status":"ok","timestamp":1747908125712,"user_tz":-330,"elapsed":10,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}},"outputId":"563b9e56-78ff-4136-bc38-a1ff0c338427"},"outputs":[{"output_type":"stream","name":"stdout","text":["tensor([-400., -400., -400.], device='cuda:0', dtype=torch.float64)\n","63999999.875\n","tensor([[0., 0., 0., 0., 0., 0.],\n","        [1., 1., 1., 1., 1., 1.]], device='cuda:0', dtype=torch.float64)\n"]}],"source":["print(problem.ref_point, end=\"\\n\")\n","print(problem.max_hv, end=\"\\n\")\n","print(problem.bounds, end=\"\\n\")"]},{"cell_type":"markdown","metadata":{"originalKey":"fc047039-c2a9-4ea8-920e-c057547cfb11","showInput":false,"id":"I31BWTdlBdhr"},"source":["#### Model initialization\n","\n","We use a list of `SingleTaskGP`s to model the two objectives with known noise variances. If no noise variances were provided, `SingleTaskGP` would infer (homoskedastic) noise levels instead.\n","\n","The models are initialized with $2(d+1)=6$ points drawn randomly from $[0,1]^2$."]},{"cell_type":"code","execution_count":43,"metadata":{"customOutput":null,"executionStartTime":1668649462312,"executionStopTime":1668649462318,"jupyter":{"outputs_hidden":false},"originalKey":"47170c31-65e4-4f2d-949c-d91544e065fc","requestMsgId":"8a44b7cb-cc5f-419e-849f-2b4d1dc3abe1","id":"hIkSW6KWBdhr","executionInfo":{"status":"ok","timestamp":1747908125717,"user_tz":-330,"elapsed":4,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["from botorch.models.gp_regression import SingleTaskGP\n","from botorch.models.model_list_gp_regression import ModelListGP\n","from botorch.models.transforms.outcome import Standardize\n","from gpytorch.mlls.sum_marginal_log_likelihood import SumMarginalLogLikelihood\n","from botorch.utils.transforms import unnormalize, normalize\n","from botorch.utils.sampling import draw_sobol_samples\n","\n","n_initial = 11 * problem.dim - 1\n","\n","def generate_initial_data(n=n_initial):\n","    # generate training data\n","    train_x = draw_sobol_samples(bounds=problem.bounds, n=n, q=1).squeeze(1)\n","    train_obj_true = problem(train_x)\n","    train_obj = train_obj_true\n","    return train_x, train_obj, train_obj_true\n","\n","\n","\n","from botorch.models.gp_regression import SingleTaskGP\n","from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n","\n","def initialize_model(train_x, train_obj):\n","    train_x = normalize(train_x, problem.bounds)\n","    train_y = train_obj  # Shape: [n, 2]\n","\n","    model = SingleTaskGP(\n","        train_x,\n","        train_y,\n","        outcome_transform=Standardize(m=3),  # Standardize both objectives\n","    )\n","    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n","    return mll, model"]},{"cell_type":"markdown","metadata":{"originalKey":"6bfaef9a-3f34-4d51-9700-fbddc79eccf1","showInput":false,"id":"Y-OuG7D3Bdhs"},"source":["#### Define a helper functions that performs the essential BO step for $q$EHVI and $q$NEHVI\n","The helper function below initializes the $q$EHVI acquisition function, optimizes it, and returns the batch $\\{x_1, x_2, \\ldots x_q\\}$ along with the observed function values.\n","\n","For this example, we'll use a relatively small batch of optimization ($q=4$). For batch optimization ($q>1$), passing the keyword argument `sequential=True` to the function `optimize_acqf`specifies that candidates should be optimized in a sequential greedy fashion (see [1] for details why this is important). A simple initialization heuristic is used to select the 10 restart initial locations from a set of 512 random points. Multi-start optimization of the acquisition function is performed using LBFGS-B with exact gradients computed via auto-differentiation.\n","\n","**Reference Point**\n","\n","$q$EHVI requires specifying a reference point, which is the lower bound on the objectives used for computing hypervolume. In this tutorial, we assume the reference point is known. In practice the reference point can be set 1) using domain knowledge to be slightly worse than the lower bound of objective values, where the lower bound is the minimum acceptable value of interest for each objective, or 2) using a dynamic reference point selection strategy.\n","\n","**Partitioning the Non-dominated Space into disjoint rectangles**\n","\n","$q$EHVI requires partitioning the non-dominated space into disjoint rectangles (see [1] for details).\n","\n","*Note:* `FastNondominatedPartitioning` *will be very slow when 1) there are a lot of points on the pareto frontier and 2) there are >5 objectives.*"]},{"cell_type":"code","execution_count":44,"metadata":{"customOutput":null,"executionStartTime":1668649462539,"executionStopTime":1668649462641,"jupyter":{"outputs_hidden":false},"originalKey":"b7effe94-1327-405d-9148-c8e93470b846","requestMsgId":"40a5edda-3bee-43c9-b84b-c669c288eb80","id":"zSOEeo1bBdhs","executionInfo":{"status":"ok","timestamp":1747908125726,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["from botorch.optim.optimize import optimize_acqf, optimize_acqf_list\n","from botorch.acquisition.objective import GenericMCObjective\n","from botorch.utils.multi_objective.scalarization import get_chebyshev_scalarization\n","from botorch.utils.multi_objective.box_decompositions.non_dominated import (\n","    NondominatedPartitioning,\n",")\n","from botorch.acquisition.multi_objective import (\n","    qLogExpectedHypervolumeImprovement,\n","    qLogNoisyExpectedHypervolumeImprovement,\n",")\n","from botorch.utils.sampling import sample_simplex\n","\n","\n","BATCH_SIZE = 2\n","NUM_RESTARTS = 10 if not SMOKE_TEST else 2\n","RAW_SAMPLES = 128 if not SMOKE_TEST else 4\n","\n","standard_bounds = torch.zeros(2, problem.dim, **tkwargs)\n","standard_bounds[1] = 1\n","\n","\n","def optimize_qehvi_and_get_observation(model, train_x, train_obj, sampler):\n","    \"\"\"Optimizes the qEHVI acquisition function, and returns a new candidate and observation.\"\"\"\n","    # partition non-dominated space into disjoint rectangles\n","    with torch.no_grad():\n","        pred = model.posterior(normalize(train_x, problem.bounds)).mean\n","    partitioning = NondominatedPartitioning(\n","        ref_point=problem.ref_point,\n","        Y=pred,\n","    )\n","    acq_func = qLogExpectedHypervolumeImprovement(\n","        model=model,\n","        ref_point=problem.ref_point,\n","        partitioning=partitioning,\n","        sampler=sampler,\n","    )\n","    # optimize\n","    candidates, _ = optimize_acqf(\n","        acq_function=acq_func,\n","        bounds=standard_bounds,\n","        q=BATCH_SIZE,\n","        num_restarts=NUM_RESTARTS,\n","        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n","        options={\"batch_limit\": 5, \"maxiter\": 200},\n","        sequential=True,\n","    )\n","    # observe new values\n","    new_x = unnormalize(candidates.detach(), bounds=problem.bounds)\n","    new_obj_true = problem(new_x)\n","    new_obj = new_obj_true\n","    return new_x, new_obj, new_obj_true"]},{"cell_type":"markdown","metadata":{"originalKey":"ad78607d-d910-441c-903b-b15dc77a432f","showInput":false,"id":"MiFVOqxhBdht"},"source":["#### Define a helper function that performs the essential BO step for $q$NParEGO\n","The helper function below similarly initializes $q$NParEGO, optimizes it, and returns the batch $\\{x_1, x_2, \\ldots x_q\\}$ along with the observed function values.\n","\n","$q$NParEGO uses random augmented chebyshev scalarization with the `qNoisyExpectedImprovement` acquisition function. In the parallel setting ($q>1$), each candidate is optimized in sequential greedy fashion using a different random scalarization (see [1] for details).\n","\n","To do this, we create a list of `qNoisyExpectedImprovement` acquisition functions, each with different random scalarization weights. The `optimize_acqf_list` method sequentially generates one candidate per acquisition function and conditions the next candidate (and acquisition function) on the previously selected pending candidates."]},{"cell_type":"code","execution_count":45,"metadata":{"customOutput":null,"executionStartTime":1668649463087,"executionStopTime":1668649463185,"jupyter":{"outputs_hidden":false},"originalKey":"806b115f-a15f-44df-b7f9-d2f098969e02","requestMsgId":"514d162f-78e0-447a-a483-c923cba18b80","id":"rACxiO2FBdht","executionInfo":{"status":"ok","timestamp":1747908125738,"user_tz":-330,"elapsed":7,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["from botorch.acquisition import qLogNoisyExpectedImprovement\n","\n","\n","def optimize_qnparego_and_get_observation(model, train_x, train_obj, sampler):\n","    \"\"\"Samples a set of random weights for each candidate in the batch, performs sequential greedy optimization\n","    of the qNParEGO acquisition function, and returns a new candidate and observation.\"\"\"\n","    train_x = normalize(train_x, problem.bounds)\n","    with torch.no_grad():\n","        pred = model.posterior(train_x).mean\n","    acq_func_list = []\n","    for _ in range(BATCH_SIZE):\n","        weights = sample_simplex(problem.num_objectives, **tkwargs).squeeze()\n","        objective = GenericMCObjective(\n","            get_chebyshev_scalarization(weights=weights, Y=pred)\n","        )\n","        acq_func = qLogNoisyExpectedImprovement(  # pyre-ignore: [28]\n","            model=model,\n","            objective=objective,\n","            X_baseline=train_x,\n","            sampler=sampler,\n","            prune_baseline=True,\n","        )\n","        acq_func_list.append(acq_func)\n","    # optimize\n","    candidates, _ = optimize_acqf_list(\n","        acq_function_list=acq_func_list,\n","        bounds=standard_bounds,\n","        num_restarts=NUM_RESTARTS,\n","        raw_samples=RAW_SAMPLES,  # used for intialization heuristic\n","        options={\"batch_limit\": 5, \"maxiter\": 200},\n","    )\n","    # observe new values\n","    new_x = unnormalize(candidates.detach(), bounds=problem.bounds)\n","    new_obj_true = problem(new_x)\n","    new_obj = new_obj_true #+ torch.randn_like(new_obj_true) * NOISE_SE\n","    return new_x, new_obj, new_obj_true"]},{"cell_type":"markdown","metadata":{"originalKey":"f8ffd86a-f4bb-4984-9330-04ff4d62f189","showInput":false,"id":"ZXq2l3l-Bdht"},"source":["### Perform Bayesian Optimization loop with $q$NEHVI, $q$EHVI, and $q$NParEGO\n","The Bayesian optimization \"loop\" for a batch size of $q$ simply iterates the following steps:\n","1. given a surrogate model, choose a batch of points $\\{x_1, x_2, \\ldots x_q\\}$\n","2. observe $f(x)$ for each $x$ in the batch\n","3. update the surrogate model.\n","\n","\n","Just for illustration purposes, we run one trial with `N_BATCH=20` rounds of optimization. The acquisition function is approximated using `MC_SAMPLES=128` samples.\n","\n","*Note*: Running this may take a little while."]},{"cell_type":"code","execution_count":46,"metadata":{"customOutput":null,"executionStartTime":1668649463513,"executionStopTime":1668649856754,"jupyter":{"outputs_hidden":false},"originalKey":"c29b731a-64e7-401d-a5b2-3879d8d39327","requestMsgId":"43e1021f-9ecd-4d2c-a7ba-21e26051ce66","id":"A2Ii-yH3Bdhu","colab":{"base_uri":"https://localhost:8080/","height":515},"executionInfo":{"status":"error","timestamp":1747909342221,"user_tz":-330,"elapsed":1216482,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}},"outputId":"5f3eb571-3ffe-4c2c-a315-f8424c0af3ca"},"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Batch  1: Hypervolume (qNParEGO, qEHVI) = (62835370.50, 62788951.75), time = 263.32.\n","Batch  2: Hypervolume (qNParEGO, qEHVI) = (63077395.56, 62796828.45), time = 328.60.\n","Batch  3: Hypervolume (qNParEGO, qEHVI) = (63077395.56, 62869194.40), time = 253.25."]},{"output_type":"error","ename":"OutOfMemoryError","evalue":"CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 2916 has 14.63 GiB memory in use. Of the allocated memory 14.28 GiB is allocated by PyTorch, and 185.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)","\u001b[0;32m<ipython-input-46-df79995792ae>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     60\u001b[0m         \u001b[0mmodel_qparego\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_qparego\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_obj_qparego\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqparego_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     )\n\u001b[0;32m---> 62\u001b[0;31m     new_x_qehvi, new_obj_qehvi, new_obj_true_qehvi = optimize_qehvi_and_get_observation(\n\u001b[0m\u001b[1;32m     63\u001b[0m         \u001b[0mmodel_qehvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_x_qehvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_obj_qehvi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mqehvi_sampler\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m     )\n","\u001b[0;32m<ipython-input-44-f3e4f29c23cd>\u001b[0m in \u001b[0;36moptimize_qehvi_and_get_observation\u001b[0;34m(model, train_x, train_obj, sampler)\u001b[0m\n\u001b[1;32m     36\u001b[0m     )\n\u001b[1;32m     37\u001b[0m     \u001b[0;31m# optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 38\u001b[0;31m     candidates, _ = optimize_acqf(\n\u001b[0m\u001b[1;32m     39\u001b[0m         \u001b[0macq_function\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0macq_func\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     40\u001b[0m         \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstandard_bounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36moptimize_acqf\u001b[0;34m(acq_function, bounds, q, num_restarts, raw_samples, options, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, fixed_features, post_processing_func, batch_initial_conditions, return_best_only, gen_candidates, sequential, ic_generator, timeout_sec, return_full_tree, retry_on_optimization_warning, **ic_gen_kwargs)\u001b[0m\n\u001b[1;32m    654\u001b[0m         \u001b[0mic_gen_kwargs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mic_gen_kwargs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    655\u001b[0m     )\n\u001b[0;32m--> 656\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_optimize_acqf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_acqf_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    657\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36m_optimize_acqf\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    672\u001b[0m     \u001b[0;31m# Perform sequential optimization via successive conditioning on pending points\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    673\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mopt_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msequential\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mopt_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 674\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0m_optimize_acqf_sequential_q\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_inputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mopt_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    675\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    676\u001b[0m     \u001b[0;31m# Batch optimization (including the case q=1)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36m_optimize_acqf_sequential_q\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    276\u001b[0m     )\n\u001b[1;32m    277\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopt_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 278\u001b[0;31m         \u001b[0mcandidate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macq_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_optimize_acqf_batch\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_inputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    279\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    280\u001b[0m         \u001b[0mcandidate_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36m_optimize_acqf_batch\u001b[0;34m(opt_inputs)\u001b[0m\n\u001b[1;32m    411\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbatch_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mopt_warnings\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    412\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 413\u001b[0;31m     \u001b[0mbatch_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_acq_values\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mws\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_optimize_batch_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    414\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m     optimization_warning_raised = any(\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/optimize.py\u001b[0m in \u001b[0;36m_optimize_batch_candidates\u001b[0;34m()\u001b[0m\n\u001b[1;32m    388\u001b[0m                     \u001b[0mbatch_candidates_curr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    389\u001b[0m                     \u001b[0mbatch_acq_values_curr\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 390\u001b[0;31m                 \u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mopt_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgen_candidates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    391\u001b[0m                     \u001b[0mbatched_ics_\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    392\u001b[0m                     \u001b[0mopt_inputs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macq_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/generation/gen.py\u001b[0m in \u001b[0;36mgen_candidates_scipy\u001b[0;34m(initial_conditions, acquisition_function, lower_bounds, upper_bounds, inequality_constraints, equality_constraints, nonlinear_inequality_constraints, options, fixed_features, timeout_sec)\u001b[0m\n\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SLSQP\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstraints\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 240\u001b[0;31m     res = minimize_with_timeout(\n\u001b[0m\u001b[1;32m    241\u001b[0m         \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mf_np_wrapper\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    242\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/optim/utils/timeout.py\u001b[0m in \u001b[0;36mminimize_with_timeout\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options, timeout_sec)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;31m# See https://github.com/scipy/scipy/issues/22438.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m         \u001b[0;32mwith\u001b[0m \u001b[0mthreadpool_limits\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlimits\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0muser_api\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"blas\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m             return optimize.minimize(\n\u001b[0m\u001b[1;32m     87\u001b[0m                 \u001b[0mfun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0mx0\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_minimize.py\u001b[0m in \u001b[0;36mminimize\u001b[0;34m(fun, x0, args, method, jac, hess, hessp, bounds, constraints, tol, callback, options)\u001b[0m\n\u001b[1;32m    736\u001b[0m                                  **options)\n\u001b[1;32m    737\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'l-bfgs-b'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 738\u001b[0;31m         res = _minimize_lbfgsb(fun, x0, args, jac, bounds,\n\u001b[0m\u001b[1;32m    739\u001b[0m                                callback=callback, **options)\n\u001b[1;32m    740\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mmeth\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'tnc'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_lbfgsb_py.py\u001b[0m in \u001b[0;36m_minimize_lbfgsb\u001b[0;34m(fun, x0, args, jac, bounds, disp, maxcor, ftol, gtol, eps, maxfun, maxiter, iprint, callback, maxls, finite_diff_rel_step, **unknown_options)\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    385\u001b[0m     \u001b[0;31m# _prepare_scalar_function can use bounds=None to represent no bounds\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 386\u001b[0;31m     sf = _prepare_scalar_function(fun, x0, jac=jac, args=args, epsilon=eps,\n\u001b[0m\u001b[1;32m    387\u001b[0m                                   \u001b[0mbounds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbounds\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    388\u001b[0m                                   finite_diff_rel_step=finite_diff_rel_step)\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_prepare_scalar_function\u001b[0;34m(fun, x0, jac, args, bounds, epsilon, finite_diff_rel_step, hess)\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;31m# ScalarFunction caches. Reuse of fun(x) during grad\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    290\u001b[0m     \u001b[0;31m# calculation reduces overall function evaluations.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 291\u001b[0;31m     sf = ScalarFunction(fun, x0, args, grad, hess,\n\u001b[0m\u001b[1;32m    292\u001b[0m                         finite_diff_rel_step, bounds, epsilon=epsilon)\n\u001b[1;32m    293\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, fun, x0, args, grad, hess, finite_diff_rel_step, finite_diff_bounds, epsilon)\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    222\u001b[0m         \u001b[0;31m# Initial function evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 223\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m         \u001b[0;31m# Initial gradient evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36m_update_fun\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    293\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_update_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    294\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_updated\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 295\u001b[0;31m             \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_wrapped_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    296\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mfx\u001b[0m \u001b[0;34m<\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_f\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lowest_x\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_differentiable_functions.py\u001b[0m in \u001b[0;36mwrapped\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     19\u001b[0m         \u001b[0;31m# Overwriting results in undefined behaviour because\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     20\u001b[0m         \u001b[0;31m# fun(self.x) will change self.x, with the two no longer linked.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 21\u001b[0;31m         \u001b[0mfx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     22\u001b[0m         \u001b[0;31m# Make sure the function returns a true scalar\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misscalar\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     78\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m         \u001b[0;34m\"\"\" returns the function value \"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_if_needed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/scipy/optimize/_optimize.py\u001b[0m in \u001b[0;36m_compute_if_needed\u001b[0;34m(self, x, *args)\u001b[0m\n\u001b[1;32m     72\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     73\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 74\u001b[0;31m             \u001b[0mfg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     75\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjac\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     76\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfg\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/generation/gen.py\u001b[0m in \u001b[0;36mf_np_wrapper\u001b[0;34m(x, f)\u001b[0m\n\u001b[1;32m    194\u001b[0m             )\n\u001b[1;32m    195\u001b[0m             \u001b[0mX_fix\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfix_features\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfixed_features\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfixed_features\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 196\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_fix\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    197\u001b[0m             \u001b[0;31m# compute gradient w.r.t. the inputs (does not accumulate in leaves)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m             \u001b[0mgradf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_arrayify\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontiguous\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mview\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/generation/gen.py\u001b[0m in \u001b[0;36mf\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 237\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0macquisition_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    238\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    239\u001b[0m     \u001b[0mmethod\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"method\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"SLSQP\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mconstraints\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"L-BFGS-B\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/utils/transforms.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(cls, X, **kwargs)\u001b[0m\n\u001b[1;32m    342\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_pending\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    343\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmatch_batch_shape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mX_pending\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 344\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    345\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    346\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdecorated\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/utils/transforms.py\u001b[0m in \u001b[0;36mdecorated\u001b[0;34m(acqf, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    296\u001b[0m             \u001b[0;31m# add t-batch dim\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    297\u001b[0m             \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mX\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m2\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munsqueeze\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 298\u001b[0;31m             \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macqf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    299\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macqf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"model\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mis_ensemble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0macqf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;31m# IDEA: this could be wrapped into SampleReducingMCAcquisitionFunction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/acquisition/multi_objective/logei.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    314\u001b[0m         \u001b[0mposterior\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    315\u001b[0m         \u001b[0msamples\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_posterior_samples\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mposterior\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 316\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compute_log_qehvi\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msamples\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    317\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    318\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/acquisition/multi_objective/logei.py\u001b[0m in \u001b[0;36m_compute_log_qehvi\u001b[0;34m(self, samples, X)\u001b[0m\n\u001b[1;32m    224\u001b[0m             \u001b[0;31m# overlap is given by the component-wise minimum.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    225\u001b[0m             \u001b[0;31m# negative of maximum of negative log_improvement is approximation to min.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 226\u001b[0;31m             log_improvement_i = self._smooth_min(\n\u001b[0m\u001b[1;32m    227\u001b[0m                 \u001b[0mlog_improvement_i\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    228\u001b[0m                 \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/acquisition/multi_objective/logei.py\u001b[0m in \u001b[0;36m_smooth_min\u001b[0;34m(self, X, dim, keepdim)\u001b[0m\n\u001b[1;32m    303\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_smooth_min\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mbool\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    304\u001b[0m         \u001b[0mf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfatmin\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfat\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0msmooth_amin\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 305\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtau_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    307\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_smooth_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0mTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/utils/safe_math.py\u001b[0m in \u001b[0;36mfatmin\u001b[0;34m(x, dim, keepdim, tau, alpha)\u001b[0m\n\u001b[1;32m    369\u001b[0m         \u001b[0mA\u001b[0m \u001b[0mTensor\u001b[0m \u001b[0mof\u001b[0m \u001b[0msmooth\u001b[0m \u001b[0mapproximations\u001b[0m \u001b[0mto\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m`\u001b[0m\u001b[0mamin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m`\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0ma\u001b[0m \u001b[0mfat\u001b[0m \u001b[0mtail\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \"\"\"\n\u001b[0;32m--> 371\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mfatmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    372\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    373\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/utils/safe_math.py\u001b[0m in \u001b[0;36mfatmax\u001b[0;34m(x, dim, keepdim, tau, alpha)\u001b[0m\n\u001b[1;32m    343\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mtau\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0m_pareto\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mx\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0mtau\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0malpha\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0malpha\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlog\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    344\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 345\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_inf_max_helper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_fun\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmax_fun\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mdim\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mkeepdim\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    346\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/botorch/utils/safe_math.py\u001b[0m in \u001b[0;36m_inf_max_helper\u001b[0;34m(max_fun, x, dim, keepdim)\u001b[0m\n\u001b[1;32m    170\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    171\u001b[0m     \u001b[0my_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m~\u001b[0m\u001b[0mis_inf_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 172\u001b[0;31m     \u001b[0mM_no_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mM\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misinf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    173\u001b[0m     \u001b[0my_no_inf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmasked_fill\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhas_inf_max\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m0.0\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mM_no_inf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    174\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 246.00 MiB. GPU 0 has a total capacity of 14.74 GiB of which 114.12 MiB is free. Process 2916 has 14.63 GiB memory in use. Of the allocated memory 14.28 GiB is allocated by PyTorch, and 185.72 MiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"]}],"source":["import time\n","import warnings\n","\n","from botorch import fit_gpytorch_mll\n","from botorch.exceptions import BadInitialCandidatesWarning\n","from botorch.sampling.normal import SobolQMCNormalSampler\n","from botorch.utils.multi_objective.box_decompositions.non_dominated import (\n","    NondominatedPartitioning,\n",")\n","from botorch.utils.multi_objective.pareto import is_non_dominated\n","\n","\n","warnings.filterwarnings(\"ignore\", category=BadInitialCandidatesWarning)\n","warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n","\n","N_BATCH = 100 if not SMOKE_TEST else 4\n","MC_SAMPLES = 64 if not SMOKE_TEST else 16\n","\n","verbose = True\n","\n","hvs_qparego, hvs_qehvi = [], []\n","\n","# call helper functions to generate initial training data and initialize model\n","train_x_qparego, train_obj_qparego, train_obj_true_qparego = generate_initial_data()\n","mll_qparego, model_qparego = initialize_model(train_x_qparego, train_obj_qparego)\n","\n","train_x_qehvi, train_obj_qehvi, train_obj_true_qehvi = (\n","    train_x_qparego,\n","    train_obj_qparego,\n","    train_obj_true_qparego,\n",")\n","mll_qehvi, model_qehvi = initialize_model(train_x_qehvi, train_obj_qehvi)\n","\n","# compute hypervolume\n","bd = NondominatedPartitioning(ref_point=problem.ref_point, Y=train_obj_true_qparego)\n","volume = bd.compute_hypervolume().item()\n","\n","hvs_qparego.append(volume)\n","hvs_qehvi.append(volume)\n","\n","# run N_BATCH rounds of BayesOpt after the initial random batch\n","for iteration in range(1, N_BATCH + 1):\n","\n","    t0 = time.monotonic()\n","\n","    # fit the models\n","    fit_gpytorch_mll(mll_qparego)\n","    fit_gpytorch_mll(mll_qehvi)\n","\n","    # define the qEI and qNEI acquisition modules using a QMC sampler\n","    qparego_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n","    qehvi_sampler = SobolQMCNormalSampler(sample_shape=torch.Size([MC_SAMPLES]))\n","\n","    # optimize acquisition functions and get new observations\n","    (\n","        new_x_qparego,\n","        new_obj_qparego,\n","        new_obj_true_qparego,\n","    ) = optimize_qnparego_and_get_observation(\n","        model_qparego, train_x_qparego, train_obj_qparego, qparego_sampler\n","    )\n","    new_x_qehvi, new_obj_qehvi, new_obj_true_qehvi = optimize_qehvi_and_get_observation(\n","        model_qehvi, train_x_qehvi, train_obj_qehvi, qehvi_sampler\n","    )\n","\n","    # update training points\n","    train_x_qparego = torch.cat([train_x_qparego, new_x_qparego])\n","    train_obj_qparego = torch.cat([train_obj_qparego, new_obj_qparego])\n","    train_obj_true_qparego = torch.cat([train_obj_true_qparego, new_obj_true_qparego])\n","\n","    train_x_qehvi = torch.cat([train_x_qehvi, new_x_qehvi])\n","    train_obj_qehvi = torch.cat([train_obj_qehvi, new_obj_qehvi])\n","    train_obj_true_qehvi = torch.cat([train_obj_true_qehvi, new_obj_true_qehvi])\n","\n","\n","    # update progress\n","    for hvs_list, train_obj in zip(\n","        (hvs_qparego, hvs_qehvi),\n","        (\n","            train_obj_true_qparego,\n","            train_obj_true_qehvi,\n","        ),\n","    ):\n","        # compute hypervolume\n","        bd = NondominatedPartitioning(ref_point=problem.ref_point, Y=train_obj)\n","        volume = bd.compute_hypervolume().item()\n","        hvs_list.append(volume)\n","\n","    # reinitialize the models so they are ready for fitting on next iteration\n","    # Note: we find improved performance from not warm starting the model hyperparameters\n","    # using the hyperparameters from the previous iteration\n","    mll_qparego, model_qparego = initialize_model(train_x_qparego, train_obj_qparego)\n","    mll_qehvi, model_qehvi = initialize_model(train_x_qehvi, train_obj_qehvi)\n","\n","    t1 = time.monotonic()\n","\n","    torch.cuda.empty_cache()\n","    gc.collect()\n","\n","    if verbose:\n","        print(\n","            f\"\\nBatch {iteration:>2}: Hypervolume (qNParEGO, qEHVI) = \"\n","            f\"({hvs_qparego[-1]:>4.2f}, {hvs_qehvi[-1]:>4.2f}), \"\n","            f\"time = {t1-t0:>4.2f}.\",\n","            end=\"\",\n","        )\n","    else:\n","        print(\".\", end=\"\")"]},{"cell_type":"markdown","metadata":{"originalKey":"72232578-0908-4292-aca4-d52197890dd6","showInput":false,"id":"v70wonHIBdhu"},"source":["### Plot the results\n","The plot below shows the a common metric of multi-objective optimization performance, the log hypervolume difference: the log difference between the hypervolume of the true pareto front and the hypervolume of the approximate pareto front identified by each algorithm. The log hypervolume difference is plotted at each step of the optimization for each of the algorithms.\n","\n","The plot shows that $q$NEHVI outperforms $q$EHVI and $q$ParEGO."]},{"cell_type":"code","execution_count":null,"metadata":{"customOutput":null,"executionStartTime":1668649857076,"executionStopTime":1668649858100,"jupyter":{"outputs_hidden":false},"originalKey":"c9560130-5c74-4b2b-b24a-fd7618ee7822","requestMsgId":"d6978d53-90e4-476b-bb1d-75010f65dcd6","scrolled":true,"id":"FyLWlXS5Bdhu","executionInfo":{"status":"aborted","timestamp":1747909342224,"user_tz":-330,"elapsed":1221479,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["import numpy as np\n","from matplotlib import pyplot as plt\n","\n","%matplotlib inline\n","\n","\n","iters = np.arange(N_BATCH + 1) * BATCH_SIZE\n","log_hv_difference_qparego = np.log10(problem.max_hv - np.asarray(hvs_qparego))\n","log_hv_difference_qehvi = np.log10(problem.max_hv - np.asarray(hvs_qehvi))\n","\n","fig, ax = plt.subplots(1, 1, figsize=(8, 6))\n","ax.errorbar(\n","    iters,\n","    log_hv_difference_qparego,\n","    label=\"qNParEGO\",\n","    linewidth=1.5,\n",")\n","ax.errorbar(\n","    iters,\n","    log_hv_difference_qehvi,\n","    label=\"qEHVI\",\n","    linewidth=1.5,\n",")\n","ax.set(\n","    xlabel=\"number of observations (beyond initial points)\",\n","    ylabel=\"Log Hypervolume Difference\",\n",")\n","ax.legend(loc=\"lower left\")"]},{"cell_type":"markdown","metadata":{"collapsed":true,"jupyter":{"outputs_hidden":true},"originalKey":"824c329c-6c02-4f67-bce0-a4c57ea655d8","showInput":false,"id":"zCutcS6HBdhv"},"source":["#### Plot the true objectives at the evaluated designs colored by iteration\n","\n","To examine optimization process from another perspective, we plot the true function values at the designs selected under each algorithm where the color corresponds to the BO iteration at which the point was collected. The plot on the right for $q$NEHVI shows that the $q$NEHVI quickly identifies the pareto front and most of its evaluations are very close to the pareto front. $q$NParEGO also identifies has many observations close to the pareto front, but relies on optimizing random scalarizations, which is a less principled way of optimizing the pareto front compared to $q$NEHVI, which explicitly attempts focuses on improving the pareto front. $q$EHVI uses the posterior mean as a plug-in estimator for the true function values at the in-sample points, whereas $q$NEHVI than integrating over the uncertainty at the in-sample designs Sobol generates random points and has few points close to the Pareto front."]},{"cell_type":"code","execution_count":null,"metadata":{"customOutput":null,"executionStartTime":1668649858641,"executionStopTime":1668649859522,"jupyter":{"outputs_hidden":false},"originalKey":"cf610a77-3e82-4c30-ac7b-f7a97fa91fa5","requestMsgId":"afb07e9c-ebaf-4a8e-90e3-ca426532de20","scrolled":true,"id":"uWk2NqHCBdhv","executionInfo":{"status":"aborted","timestamp":1747909342225,"user_tz":-330,"elapsed":1221478,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["# from matplotlib.cm import ScalarMappable\n","\n","\n","# pareto_front = -problem.gen_pareto_front(n=1000).cpu().numpy()\n","\n","# fig, axes = plt.subplots(1, 2, figsize=(18, 7), sharex=True, sharey=True)\n","# algos = [\"qNParEGO\", \"qEHVI\"]\n","# cm = plt.get_cmap(\"viridis\")\n","\n","# batch_number = torch.cat(\n","#     [\n","#         torch.zeros(11 * problem.dim - 1),\n","#         torch.arange(1, N_BATCH + 1).repeat(BATCH_SIZE, 1).t().reshape(-1),\n","#     ]\n","# ).numpy()\n","# for i, train_obj in enumerate(\n","#     (\n","#         train_obj_true_qparego,\n","#         train_obj_true_qehvi,\n","#     )\n","# ):\n","#     sc = axes[i].scatter(\n","#         -train_obj[:, 0].cpu().numpy(),\n","#         -train_obj[:, 1].cpu().numpy(),\n","#         c=batch_number,\n","#         alpha=0.8,\n","#     )\n","#     axes[i].plot(pareto_front[:, 0], pareto_front[:, 1], \"r--\", label=\"Pareto Front\")\n","#     axes[i].set_title(algos[i])\n","#     axes[i].set_xlabel(\"Objective 1\")\n","#     axes[i].legend()\n","# axes[0].set_ylabel(\"Objective 2\")\n","# norm = plt.Normalize(batch_number.min(), batch_number.max())\n","# sm = ScalarMappable(norm=norm, cmap=plt.get_cmap(\"viridis\"))\n","# sm.set_array([])\n","# fig.subplots_adjust(right=0.9)\n","# cbar_ax = fig.add_axes([0.93, 0.15, 0.01, 0.7])\n","# cbar = fig.colorbar(sm, cax=cbar_ax)\n","# cbar.ax.set_title(\"Iteration\")"]},{"cell_type":"code","source":["# import matplotlib.pyplot as plt\n","\n","# # Assume train_obj_true_qparego and train_obj_true_qehvi are torch tensors\n","# # and problem.dim is defined, as well as pareto_front\n","\n","# fig, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True, sharey=True)\n","# algos = [\"qNParEGO\", \"qEHVI\"]\n","\n","# for i, train_obj in enumerate((train_obj_true_qparego, train_obj_true_qehvi)):\n","#     axes[i].scatter(\n","#         -train_obj[:n_initial, 0].cpu().numpy(),\n","#         -train_obj[:n_initial, 1].cpu().numpy(),\n","#         c=\"deepskyblue\", s=80, alpha=0.8, label=\"Training Points\"\n","#     )\n","#     axes[i].plot(\n","#         pareto_front[:, 0], pareto_front[:, 1], \"r--\", label=\"Pareto Front\"\n","#     )\n","#     axes[i].set_title(algos[i])\n","#     axes[i].set_xlabel(\"Objective 1\")\n","#     axes[i].legend()\n","# axes[0].set_ylabel(\"Objective 2\")\n","# plt.tight_layout()\n","# plt.show()\n"],"metadata":{"id":"328eqjxR4XCR","executionInfo":{"status":"aborted","timestamp":1747909342231,"user_tz":-330,"elapsed":1221483,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# import matplotlib.pyplot as plt\n","# import numpy as np\n","# from matplotlib.cm import ScalarMappable\n","# from plotly.subplots import make_subplots\n","# import plotly.graph_objects as go\n","\n","# # Generate the Pareto front (assuming this is already defined)\n","# pareto_front = -problem.gen_pareto_front(n=1000).cpu().numpy()\n","\n","# # Number of points per batch\n","# batch_size = 50\n","\n","# # Plot batches of points after skipping initial training points\n","# def plot_batches_after_training(train_obj_true_qparego, train_obj_true_qehvi, pareto_front, n_initial, batch_size):\n","#     algos = [\"qNParEGO\", \"qEHVI\"]\n","#     train_objs = [train_obj_true_qparego, train_obj_true_qehvi]\n","\n","#     # Calculate total points in each train_obj\n","#     total_points = train_obj_true_qparego.shape[0]\n","\n","#     # Calculate number of points after initial training\n","#     n_remaining = total_points - n_initial\n","\n","#     # Calculate number of plots needed\n","#     n_plots = (n_remaining + batch_size - 1) // batch_size\n","\n","#     for plot_idx in range(n_plots):\n","#         fig, axes = plt.subplots(1, 2, figsize=(15, 7), sharex=True, sharey=True)\n","#         cm = plt.get_cmap(\"viridis\")\n","\n","#         start_idx = n_initial + plot_idx * batch_size\n","#         end_idx = min(start_idx + batch_size, total_points)\n","\n","#         for i, train_obj in enumerate(train_objs):\n","#             # Get the current batch of points\n","#             batch_points = train_obj[start_idx:end_idx]\n","\n","#             # Generate indices for coloring (relative to this batch)\n","#             indices = np.arange(end_idx - start_idx)\n","\n","#             # Plot the points\n","#             sc = axes[i].scatter(\n","#                 -batch_points[:, 0].cpu().numpy(),\n","#                 -batch_points[:, 1].cpu().numpy(),\n","#                 c=indices,\n","#                 cmap=cm,\n","#                 alpha=0.8\n","#             )\n","\n","#             # Plot Pareto front\n","#             axes[i].plot(pareto_front[:, 0], pareto_front[:, 1], \"r--\", label=\"Pareto Front\")\n","\n","#             # Set titles and labels\n","#             axes[i].set_title(f\"{algos[i]} (Batch {plot_idx+1}: {len(indices)} points)\")\n","#             axes[i].set_xlabel(\"Objective 1\")\n","#             axes[i].legend()\n","\n","#         axes[0].set_ylabel(\"Objective 2\")\n","\n","#         # Add colorbar\n","#         norm = plt.Normalize(indices.min(), indices.max())\n","#         sm = ScalarMappable(norm=norm, cmap=cm)\n","#         sm.set_array([])\n","#         fig.subplots_adjust(right=0.9)\n","#         cbar_ax = fig.add_axes([0.93, 0.15, 0.01, 0.7])\n","#         cbar = fig.colorbar(sm, cax=cbar_ax)\n","#         cbar.ax.set_title(\"Point Index\")\n","\n","#         plt.tight_layout(rect=[0, 0, 0.92, 1])\n","#         plt.show()\n","\n","# # Call the function to generate the plots\n","# plot_batches_after_training(train_obj_true_qparego, train_obj_true_qehvi, pareto_front, n_initial, batch_size)\n"],"metadata":{"id":"cbz-yjOu4bzq","executionInfo":{"status":"aborted","timestamp":1747909342236,"user_tz":-330,"elapsed":1221486,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# def plot_pareto_front_2d(train_obj_true_qparego, train_obj_true_qehvi, pareto_front=None):\n","#     if pareto_front is None:\n","#         pareto_front = -problem.gen_pareto_front(n=1000).cpu().numpy()\n","\n","#     fig = make_subplots(rows=1, cols=2,\n","#                        subplot_titles=(\"qNParEGO\", \"qEHVI\"),\n","#                        horizontal_spacing=0.1)\n","\n","#     batch_number = torch.cat(\n","#         [\n","#             torch.zeros(n_initial),\n","#             torch.arange(1, N_BATCH + 1).repeat(BATCH_SIZE, 1).t().reshape(-1),\n","#         ]\n","#     ).numpy()\n","\n","#     for i, (train_obj, title) in enumerate([(train_obj_true_qparego, \"qNParEGO\"),\n","#                                            (train_obj_true_qehvi, \"qEHVI\")], 1):\n","#         # Convert to numpy\n","#         obj_np = -train_obj.cpu().numpy()\n","\n","#         # Add scatter plot for objective values\n","#         fig.add_trace(\n","#             go.Scatter(\n","#                 x=obj_np[:, 0],\n","#                 y=obj_np[:, 1],\n","#                 mode='markers',\n","#                 marker=dict(\n","#                     size=8,\n","#                     color=batch_number[:len(obj_np)],\n","#                     colorscale='Viridis',\n","#                     colorbar=dict(title='Iteration') if i == 2 else None,\n","#                     opacity=0.7\n","#                 ),\n","#                 name=title\n","#             ),\n","#             row=1, col=i\n","#         )\n","\n","#         # Add Pareto front\n","#         fig.add_trace(\n","#             go.Scatter(\n","#                 x=pareto_front[:, 0],\n","#                 y=pareto_front[:, 1],\n","#                 mode='lines',\n","#                 line=dict(color='red', width=2),\n","#                 name='True Pareto Front'\n","#             ),\n","#             row=1, col=i\n","#         )\n","\n","#     # Update layout\n","#     fig.update_layout(\n","#         height=500,\n","#         width=1200,\n","#         showlegend=False,\n","#         title_text=\"Objective Space - DTLZ1a with 2 Objectives\",\n","#     )\n","\n","#     # Set consistent axis ranges\n","#     fig.update_xaxes(title_text=\"Objective 1\", range=[0, 0.5], row=1, col=1)\n","#     fig.update_yaxes(title_text=\"Objective 2\", range=[0, 0.5], row=1, col=1)\n","#     fig.update_xaxes(title_text=\"Objective 1\", range=[0, 0.5], row=1, col=2)\n","#     fig.update_yaxes(title_text=\"Objective 2\", range=[0, 0.5], row=1, col=2)\n","\n","#     return fig\n","\n","# plot_pareto_front_2d(train_obj_true_qparego, train_obj_true_qehvi)"],"metadata":{"id":"93EOnepy-IC0","executionInfo":{"status":"aborted","timestamp":1747909342237,"user_tz":-330,"elapsed":1221486,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["####plots if is obj =3"],"metadata":{"id":"rEgC0R4V6cxc"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"mg_wnvuzQvVN","executionInfo":{"status":"aborted","timestamp":1747909342238,"user_tz":-330,"elapsed":1221486,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["import plotly.graph_objects as go\n","import plotly.io as pio\n","from plotly.subplots import make_subplots\n","import numpy as np\n","\n","def create_pareto_surface(problem, n=1000):\n","    # Generate Pareto front using the problem's built-in method\n","    pareto_front = -problem.gen_pareto_front(n).cpu().numpy()\n","\n","    if problem.num_objectives == 3:\n","        # Create Mesh3d trace for 3D problems\n","        return go.Mesh3d(\n","            x=pareto_front[:, 0],\n","            y=pareto_front[:, 1],\n","            z=pareto_front[:, 2],\n","            color='red',\n","            opacity=0.3,\n","            intensity=pareto_front[:, 2],\n","            colorscale='Reds',\n","            showscale=False,\n","            name='Pareto Front'\n","        )\n","    else:\n","        raise ValueError(\"Only 3D visualization is supported in this implementation\")\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3nhpwmwhSHVO","executionInfo":{"status":"aborted","timestamp":1747909342239,"user_tz":-330,"elapsed":1221486,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["# 1. Plot showing just initial training points\n","fig_initial = make_subplots(\n","    rows=1, cols=2,\n","    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n","    subplot_titles=(\"qNParEGO\", \"qEHVI\")\n",")\n","\n","# Generate Pareto surface using problem's built-in method\n","pf_surface = create_pareto_surface(problem)\n","\n","alg_data_initial = [\n","    (-train_obj_true_qparego[:n_initial], \"qNParEGO\"),\n","    (-train_obj_true_qehvi[:n_initial], \"qEHVI\"),\n","]\n","\n","for col, (train_obj, name) in enumerate(alg_data_initial, 1):\n","    obj_np = train_obj.cpu().numpy() if isinstance(train_obj, torch.Tensor) else train_obj\n","\n","    # Plot initial points\n","    scatter = go.Scatter3d(\n","        x=obj_np[:, 0], y=obj_np[:, 1], z=obj_np[:, 2],\n","        mode='markers',\n","        marker=dict(size=4, color='deepskyblue', opacity=0.8),\n","        name=name\n","    )\n","\n","    fig_initial.add_trace(scatter, row=1, col=col)\n","    fig_initial.add_trace(pf_surface, row=1, col=col)\n","\n","# Update layout\n","fig_initial.update_layout(\n","    height=600,\n","    width=1200,\n","    scene1=dict(\n","        xaxis_title='Objective 1',\n","        yaxis_title='Objective 2',\n","        zaxis_title='Objective 3',\n","        camera=dict(eye=dict(x=1.5, y=1.5, z=0.6))\n","    ),\n","    scene2=dict(\n","        xaxis_title='Objective 1',\n","        yaxis_title='Objective 2',\n","        zaxis_title='Objective 3',\n","        camera=dict(eye=dict(x=1.5, y=1.5, z=0.6))\n","    ),\n","    showlegend=False,\n","    title_text='Initial Training Points'\n",")\n","fig_initial.show()\n","\n","pio.write_html(fig_initial, 'DTLZ1a train.html')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"E2uIQhy7SOAi","executionInfo":{"status":"aborted","timestamp":1747909342285,"user_tz":-330,"elapsed":1221531,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["# Plot ALL points after initial training\n","fig = make_subplots(\n","    rows=1, cols=2,\n","    specs=[[{'type': 'scatter3d'}, {'type': 'scatter3d'}]],\n","    subplot_titles=(\"qNParEGO\", \"qEHVI\")\n",")\n","\n","batch_number = torch.cat([\n","    torch.zeros(n_initial),\n","    torch.arange(1, N_BATCH + 1).repeat(BATCH_SIZE, 1).t().reshape(-1),\n","]).numpy()\n","\n","start_idx = n_initial\n","end_idx = len(train_obj_true_qparego)\n","\n","alg_data = [\n","    (-train_obj_true_qparego[start_idx:end_idx], \"qNParEGO\"),\n","    (-train_obj_true_qehvi[start_idx:end_idx], \"qEHVI\"),\n","]\n","\n","for col, (train_obj, name) in enumerate(alg_data, 1):\n","    obj_np = train_obj.cpu().numpy()\n","\n","    scatter = go.Scatter3d(\n","        x=obj_np[:, 0], y=obj_np[:, 1], z=obj_np[:, 2],\n","        mode='markers',\n","        marker=dict(\n","            size=4,\n","            color=batch_number[start_idx:end_idx],\n","            colorscale='Viridis',\n","            opacity=0.8,\n","            colorbar=dict(title='Iteration') if col == 2 else None\n","        ),\n","        name=name,\n","        hovertemplate=\"<b>Obj1</b>: %{x:.2f}<br><b>Obj2</b>: %{y:.2f}<br><b>Obj3</b>: %{z:.2f}<extra></extra>\"\n","    )\n","\n","    fig.add_trace(scatter, row=1, col=col)\n","    fig.add_trace(pf_surface, row=1, col=col)\n","\n","# Update layout\n","fig.update_layout(\n","    height=600,\n","    width=1200,\n","    scene1=dict(\n","        xaxis_title='Objective 1',\n","        yaxis_title='Objective 2',\n","        zaxis_title='Objective 3',\n","        camera=dict(eye=dict(x=1.5, y=1.5, z=0.6))\n","    ),\n","    scene2=dict(\n","        xaxis_title='Objective 1',\n","        yaxis_title='Objective 2',\n","        zaxis_title='Objective 3',\n","        camera=dict(eye=dict(x=1.5, y=1.5, z=0.6))\n","    ),\n","    showlegend=False,\n","    title_text=f'All {end_idx - start_idx} Points After Initial Training'\n",")\n","\n","fig.show()\n","\n","\n","pio.write_html(fig, 'DTLZ1a candidates.html')"]},{"cell_type":"code","execution_count":null,"metadata":{"scrolled":true,"id":"9LzcVovZBdhv","executionInfo":{"status":"aborted","timestamp":1747909342286,"user_tz":-330,"elapsed":1221531,"user":{"displayName":"Deepak L","userId":"17343563887203968144"}}},"outputs":[],"source":["import pandas as pd\n","\n","# Convert PyTorch tensors to numpy arrays\n","train_x_qparego_np = train_x_qparego.cpu().numpy()\n","train_obj_qparego_np = train_obj_qparego.cpu().numpy()\n","train_x_qehvi_np = train_x_qehvi.cpu().numpy()\n","train_obj_qehvi_np = train_obj_qehvi.cpu().numpy()\n","\n","# Concatenate the input dimensions and objectives horizontally\n","qparego_data = np.hstack([train_x_qparego_np, train_obj_qparego_np])\n","qehvi_data = np.hstack([train_x_qehvi_np, train_obj_qehvi_np])\n","\n","# Create column headers for better readability\n","input_dim = train_x_qparego.shape[1]\n","obj_dim = train_obj_qparego.shape[1]\n","column_names = [f\"dim{i+1}\" for i in range(input_dim)] + [f\"obj{i+1}\" for i in range(obj_dim)]\n","\n","# Create DataFrames with the combined data and column names\n","qparego_df = pd.DataFrame(qparego_data, columns=column_names)\n","qehvi_df = pd.DataFrame(qehvi_data, columns=column_names)\n","\n","# Save to CSV files\n","qparego_df.to_csv('DTLZ1a (6-3) qNParEGO_data.csv', index=False, mode='w')\n","qehvi_df.to_csv('DTLZ1a (6-3) qEHVI_data.csv', index=False, mode='w')\n","\n","print(\"ParEGO data saved to 'DTLZ1a (6-3) qNParEGO_data.csv'\")\n","print(\"EHVI data saved to 'DTLZ1a (6-3) qEHVI_data.csv'\")\n"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.12.9"},"colab":{"provenance":[],"gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":0}